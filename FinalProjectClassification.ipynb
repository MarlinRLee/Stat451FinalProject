{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3debc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import datetime\n",
    "\n",
    "import talib as ta\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e050caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DfMain = pd.read_csv(\"C:/Users/marli/Downloads/FinalStocksDFHighResolutionMin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6e55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "import multiprocessing\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPrep(DF,Stock):\n",
    "    Df = DF[DF[\"Symbol\"]==Stock]\n",
    "    Df = Df.rename(columns={'Datetime': 'Time'}) \n",
    "    Df = Df.drop(Df[Df['Volume'] == 0].index)\n",
    "    Df['Time'] = pd.to_datetime(Df['Time'])\n",
    "    Df = Df.drop([\"IPO Year\"], axis=1)\n",
    "    Df.set_index('Time', inplace=True)\n",
    "    n = 10\n",
    "    Df['RSI'] = ta.RSI(np.array(Df['Close'].shift(1)), timeperiod=n)\n",
    "    Df['SMA'] = Df['Close'].shift(1).rolling(window=n).mean()\n",
    "    Df['Corr'] = Df['Close'].shift(1).rolling(window=n).corr(Df['SMA'].shift(1))\n",
    "    Df['SAR'] = ta.SAR(np.array(Df['High'].shift(1)),\n",
    "                   np.array(Df['Low'].shift(1)), 0.2, 0.2)\n",
    "    Df['ADX'] = ta.ADX(np.array(Df['High'].shift(1)), np.array(\n",
    "    Df['Low'].shift(1)), np.array(Df['Open']), timeperiod=n)\n",
    "    Df['OpenShifted'] = Df['Open'].shift(1)\n",
    "    Df['CloseShifted'] = Df['Close'].shift(1)\n",
    "    Df['HighShifted'] = Df['High'].shift(1)\n",
    "    Df['LowShifted'] = Df['Low'].shift(1)\n",
    "    Df['OO'] = Df['Open']-Df['OpenShifted']\n",
    "    Df['OC'] = Df['Open']-Df['CloseShifted']\n",
    "    Df['Ret'] = (Df['Open'].shift(-1)-Df['Open'])/Df['Open']\n",
    "    for i in range(1, n):\n",
    "        Df['return%i' % i] = Df['Ret'].shift(i)\n",
    "    #Trimming the dataDF\n",
    "    Df.loc[Df['Corr'] < -1, 'Corr'] = -1\n",
    "    Df.loc[Df['Corr'] > 1, 'Corr'] = 1\n",
    "    Df = Df.dropna()\n",
    "    return(Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XYPrep(DF,t=.8):\n",
    "    split = int(t*len(DF))\n",
    "    Df = DF\n",
    "    #Creating output signal\n",
    "    Df['Signal'] = 0#\n",
    "    Df.loc[Df['Ret'] > Df['Ret'][:split].quantile(q=0.66), 'Signal'] = -1\n",
    "    Df.loc[Df['Ret'] < Df['Ret'][:split].quantile(q=0.33), 'Signal'] = 1\n",
    "    #Df.loc[Df['Ret'] > Df['Ret'][:split].quantile(q=0.8), 'Signal'] = 2\n",
    "    #Df.loc[Df['Ret'] < Df['Ret'][:split].quantile(q=0.2), 'Signal'] = -2\n",
    "    \n",
    "    # Assign a value of 0 to 'Signal' column at 1529 time\n",
    "    Df.loc[(Df.index.hour == 15) & (Df.index.minute == 29), 'Signal'] = 0\n",
    "    # Assign a value of 0 to 'Fut_Ret' column at 1529 time\n",
    "    #Df.loc[(Df.index.hour == 15) & (Df.index.minute == 29), 'Fut_Ret'] = 0\n",
    "    split = int(t*len(Df))\n",
    "    TestDf = Df.iloc[split:]\n",
    "    TrainDf = Df.iloc[:split]\n",
    "    return(TrainDf,TestDf)\n",
    "\n",
    "def DataSplit(DF):\n",
    "    # Creating the features and values\n",
    "    X = DF.drop(['Close', 'Signal', 'High','Open',\n",
    "            'Low', 'Ret',\"Name\",\"Dividends\", \"Country\",'Market Cap','Volume', \"Symbol\",\n",
    "             \"Sector\",\"Industry\",\"Stock Splits\"], axis=1)\n",
    "    Y = DF['Signal']\n",
    "    Ret = DF['Ret']\n",
    "    return(X,Y,Ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainFit(X_Train,Y_Train,Model,parameters):\n",
    "\n",
    "    steps = [('scaler', StandardScaler()), ('Model', Model)]\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    clf = GridSearchCV(pipeline,parameters, cv=5 , verbose=0,n_jobs=1,scoring = \"f1_macro\")#Not sure if this is best metric\n",
    "    clf.fit(X_Train, Y_Train)\n",
    "    #print(clf.best_score_)\n",
    "    #print(clf.best_params_)\n",
    "\n",
    "    pipeline.set_params(**clf.best_params_)\n",
    "    pipeline.fit(X_Train, Y_Train)\n",
    "    return(pipeline)\n",
    "\n",
    "def TestModel(Mod,X_Test,Y_Test,Ret_Test,Name = \"Model\"):\n",
    "    predictions = Mod.predict(X_Test)\n",
    "    #cm = confusion_matrix(Y_Test, predictions, labels=Mod.classes_)\n",
    "\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "    #                           display_labels=Mod.classes_)\n",
    "    #disp.plot()\n",
    "    StragyReturn = Ret_Test*predictions\n",
    "    accuracy = accuracy_score(Y_Test, predictions)          \n",
    "    recall = recall_score(Y_Test,predictions,average=None)\n",
    "    precision = precision_score(Y_Test,predictions,average=None)\n",
    "    DF = pd.DataFrame(np.array([[StragyReturn.mean(), recall[0], recall[1],recall[1]\n",
    "                                 , precision[0], precision[1],precision[1],accuracy]]),\n",
    "                   columns=[f\"{Name} StragyReturn\", f\"{Name} recall -1\", f\"{Name} recall 0\",f\"{Name} recall 1\",\n",
    "                            f\"{Name} precision -1 \",f\"{Name} precision 0\",f\"{Name} precision 1\",f\"{Name} accuracy\"])\n",
    "    return(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba04350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Driver(DfMain,StockName):\n",
    "    Df = DataPrep(DfMain, StockName)\n",
    "    TrainDf,TestDf = XYPrep(Df)\n",
    "    X_Test,Y_Test,Ret_Test = DataSplit(TestDf)\n",
    "    X_Train,Y_Train,Ret_Train = DataSplit(TrainDf)\n",
    "    TrainedModel = TrainFit(X_Train,Y_Train,Model = GradientBoostingClassifier(), parameters = {'Model__max_depth': [1,2,4], \n",
    "              'Model__n_estimators': [50, 100],\n",
    "               'Model__min_weight_fraction_leaf': [.1],\n",
    "              'Model__learning_rate': [.9]})\n",
    "    Results1=TestModel(TrainedModel,X_Test,Y_Test,Ret_Test,Name = \"XGB\")\n",
    "    TrainedModel2 = TrainFit(X_Train,Y_Train,Model = RandomForestClassifier(), \n",
    "                             parameters = {'Model__n_estimators': [100, 200,400]})\n",
    "    Results2=TestModel(TrainedModel2,X_Test,Y_Test,Ret_Test,Name = \"RandomForest\")\n",
    "    \n",
    "    TrainedModel3 = TrainFit(X_Train,Y_Train,Model = KNeighborsClassifier(), \n",
    "                             parameters = {'Model__n_neighbors': [1, 5,20]})\n",
    "    \n",
    "    Results3 = TestModel(TrainedModel3,X_Test,Y_Test,Ret_Test,Name = \"KNN\")\n",
    "    \n",
    "    TrainedModel4 = TrainFit(X_Train,Y_Train,Model = StackingClassifier(estimators=[('XGB', GradientBoostingClassifier()),\n",
    "                                                                                    ('KNN', KNeighborsClassifier())],\n",
    "                                                                        final_estimator=LogisticRegression()), \n",
    "                             parameters = {'Model__XGB__max_depth': [1,2,4], \n",
    "                            'Model__XGB__n_estimators': [50, 100],\n",
    "                            'Model__XGB__min_weight_fraction_leaf': [.1],\n",
    "                            'Model__XGB__learning_rate': [.9],\n",
    "                            'Model__KNN__n_neighbors': [1, 5,20]})\n",
    "    \n",
    "    Results4 = TestModel(TrainedModel4,X_Test,Y_Test,Ret_Test,Name = \"Stacking\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    DFMainInfo = Df.head(1)[[\"Symbol\",\"Name\",\"Market Cap\",\"Country\",\"Sector\",\"Industry\"]]\n",
    "    \n",
    "    DFMainInfo.reset_index(drop=True, inplace=True)\n",
    "    ReturnDF = pd.concat([DFMainInfo, Results1, Results2, Results3,Results4], axis=1)\n",
    "    return(ReturnDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82753e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Driver(DfMain, \"MSFT\")\n",
    "#Df = DataPrep(DfMain, \"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145dc11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.metrics import SCORERS\n",
    "#sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637a469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started working on AA\n",
      "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Started working on AAC\n",
      "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Started working on AACG\n",
      "Started working on AACI\n",
      "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Started working on AACIU\n",
      "inputs are all NaN\n",
      "Started working on AACIW\n",
      "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Started working on AADI\n",
      "Started working on AAIC\n",
      "Started working on AAIC^B\n",
      "inputs are all NaN\n",
      "Started working on AAIC^C\n",
      "inputs are all NaN\n",
      "Started working on AAIN\n",
      "inputs are all NaN\n",
      "Started working on AAL\n",
      "Started working on AAMC\n",
      "Started working on AAME\n",
      "Started working on AAN\n",
      "Started working on AAOI\n",
      "Started working on AAON\n",
      "Started working on AAP\n",
      "Started working on AAPL\n",
      "Started working on AAQC\n",
      "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Started working on AAT\n",
      "Started working on AATC\n",
      "Started working on AAU\n",
      "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Started working on AAWW\n",
      "Started working on AB\n",
      "Started working on ABB\n",
      "Started working on ABBV\n"
     ]
    }
   ],
   "source": [
    "raise Exception\n",
    "StockNameDF = pd.read_csv(\"C:\\\\Users\\\\marli\\\\Downloads\\\\nasdaq_screener_1637446085891.csv\")\n",
    "\n",
    "StockInfo = StockNameDF[[\"Symbol\",\"Name\", \"Market Cap\", \"Country\", \"IPO Year\",\"Sector\",\"Industry\"]]\n",
    "\n",
    "StockNames = StockInfo[\"Symbol\"]\n",
    "\n",
    "NewDF = pd.read_csv(\"C:\\\\Users\\\\marli\\\\Downloads\\\\FinalAnalysisMin2.csv\")\n",
    "\n",
    "StockNamesAlreadyDone = list(NewDF[\"Symbol\"])\n",
    "\n",
    "new_strings = []\n",
    "for string in StockNames:\n",
    "    new_string = string.replace(\"/\", \"\")\n",
    "    new_strings.append(new_string)\n",
    "StockNames = new_strings\n",
    "\n",
    "i=0\n",
    "try:\n",
    "    for Name in StockNames:\n",
    "        if (Name in StockNamesAlreadyDone):\n",
    "            continue\n",
    "        #if(i%30!=2):\n",
    "        #    continue\n",
    "        print(\"Started working on {}\".format(Name))\n",
    "        try:\n",
    "            if(i==0):\n",
    "                MainDF2 = Driver(DfMain, Name)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        i+=1\n",
    "        print(i)\n",
    "        try:\n",
    "            Biz = Driver(DfMain, Name)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        print(Biz[[\"Symbol\",\"Stacking accuracy\"]])\n",
    "        MainDF2 = pd.concat([MainDF2, Biz], axis=0)\n",
    "except Exception as e :\n",
    "    print(e)\n",
    "    MainDF2.to_csv(\"C:\\\\Users\\\\marli\\\\Downloads\\\\FinalAnalysisMin.csv\")\n",
    "    raise e\n",
    "MainDF2.to_csv(\"C:\\\\Users\\\\marli\\\\Downloads\\\\FinalAnalysisMin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87832373",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainDF2.to_csv(\"C:\\\\Users\\\\marli\\\\Downloads\\\\FinalAnalysisMin2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034dbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split = int(.8*len(Df))\n",
    "#Df['Ret'].hist(bins=200)\n",
    "#plt.axvline(x=Df['Ret'][:split].quantile(q=0.66),color='r')\n",
    "#plt.axvline(x=Df['Ret'][:split].quantile(q=0.33),color='r')\n",
    "#lt.axvline(x=Df['Ret'][:split].quantile(q=0.8),color='r')\n",
    "#plt.axvline(x=Df['Ret'][:split].quantile(q=0.2),color='r')\n",
    "#Y_Test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainedModel2 = TrainFit(X_Train,Y_Train,Model = SVC(), parameters = {'Model__C': [10, 100, 1000, 10000], \n",
    "#                                                'Model__gamma': [1e-2, 1e-1, 1e0], 'Model__kernel': ['rbf']})\n",
    "#TestModel(TrainedModel2,X_Test,Y_Test,Ret_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainedModel3 = TrainFit(X_Train,Y_Train,Model = RandomForestClassifier(), parameters = {'Model__n_estimators': [100, 200]})\n",
    "#TestModel(TrainedModel3,X_Test,Y_Test,Ret_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7cedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainedModel4 = TrainFit(X_Train,Y_Train,Model = XGBClassifier(), parameters = {'Model__random_state': [123], \"Model__verbosity\":[0], 'Model__use_label_encoder':[False]})\n",
    "#TestModel(TrainedModel4,X_Test,Y_Test,Ret_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4408f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainedModel5 = TrainFit(X_Train,Y_Train,Model = LogisticRegression(), parameters = {'Model__random_state': [123]})\n",
    "#TestModel(TrainedModel5,X_Test,Y_Test,Ret_Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
